# ü§ñ Instalaci√≥n y Configuraci√≥n de Ollama + llama2/llama3.2

Tu chatbot de Trendo POS ha sido actualizado para usar **Ollama** con **llama2** (o llama3.2), un modelo de IA local m√°s potente y vers√°til que el anterior sistema basado en reglas.

## ¬øQu√© es Ollama?

Ollama es una herramienta que te permite ejecutar modelos de IA localmente en tu computadora sin necesidad de internet ni APIs en la nube. Esto significa:
- ‚úÖ Privacidad total - tus datos nunca salen de tu equipo
- ‚úÖ Sin costo - no pagas por API calls
- ‚úÖ Disponible sin internet
- ‚úÖ Respuestas m√°s inteligentes y contextuales

## Pasos de Instalaci√≥n

### 1Ô∏è‚É£ Descargar Ollama

Ve a [ollama.ai](https://ollama.ai) y descarga la versi√≥n para Windows.

### 2Ô∏è‚É£ Instalar Ollama

1. Ejecuta el instalador que descargaste
2. Sigue los pasos de instalaci√≥n (acepta los valores por defecto)
3. Ollama se instalar√° y se ejecutar√° autom√°ticamente

### 3Ô∏è‚É£ Descargar el Modelo

Una vez que Ollama est√° instalado, abre **PowerShell** o **CMD** y ejecuta:

```powershell
ollama pull llama2
```

Esto descargar√° el modelo llama2 (~4GB). Puede tomar algunos minutos.

**Alternativa (m√°s reciente):**
```powershell
ollama pull llama2-uncensored
```

O si prefieres esperar a llama3.2:
```powershell
ollama pull llama3.2
```

### 4Ô∏è‚É£ Verificar que Funciona

En la terminal, ejecuta:
```powershell
ollama serve
```

Deber√≠as ver algo como:
```
starting ollama serve
```

¬°Excelente! Ollama est√° ejecut√°ndose en `http://localhost:11434`

### 5Ô∏è‚É£ Usar el Chatbot

Ahora puedes:
1. Abrir Trendo POS
2. Hacer clic en el bot√≥n del chatbot
3. Escribe cualquier pregunta sobre tu negocio:
   - "¬øCu√°les son mis ingresos totales?"
   - "¬øQu√© productos se venden m√°s?"
   - "¬øCu√°l es mi margen de ganancia?"
   - O cualquier otra pregunta relacionada con tu POS

## Comandos √ötiles de Ollama

```powershell
# Ver modelos instalados
ollama list

# Descargar otro modelo
ollama pull llama2:13b

# Eliminar un modelo
ollama rm llama2

# Ejecutar un modelo directamente en terminal
ollama run llama2
```

## Soluci√≥n de Problemas

### Error: "Ollama no est√° disponible"

**Causa:** Ollama no est√° ejecut√°ndose

**Soluci√≥n:**
1. Abre PowerShell
2. Ejecuta: `ollama serve`
3. Vuelve a intentar en el chatbot

### Error: "Conexi√≥n rechazada"

**Causa:** El servicio de Ollama no est√° activo

**Soluci√≥n:**
1. Verifica que ejecutaste `ollama serve` en una terminal
2. Deja esa ventana abierta mientras usas Trendo POS

### El chatbot tarda mucho en responder

**Causa:** Tu computadora necesita m√°s recursos o el modelo es grande

**Soluciones:**
- Cierra otras aplicaciones pesadas
- Considera usar `llama2:7b` en lugar de `llama2:13b` si usaste el 13b
- Aguarda a que la primera respuesta se procese (las siguientes son m√°s r√°pidas)

### Error: "Modelo no encontrado"

**Causa:** El modelo no fue descargado correctamente

**Soluci√≥n:**
```powershell
ollama pull llama2
```

## Configuraci√≥n Recomendada

Para Trendo POS, recomendamos:

### Si tu PC es potente (16GB+ RAM):
```powershell
ollama pull llama2:13b
```

### Si tu PC tiene recursos limitados (8GB RAM):
```powershell
ollama pull llama2:7b
```

### Si quieres lo m√°s r√°pido (menos preciso):
```powershell
ollama pull orca-mini:3b
```

## Cambiar el Modelo

Si quieres cambiar de modelo, edita el archivo:
```
src/renderer/src/services/ollamaService.js
```

En la l√≠nea 6, cambia:
```javascript
const OLLAMA_MODEL = 'llama2' // Cambiar a 'llama3.2' cuando est√© instalado
```

Por el modelo que prefieras:
```javascript
const OLLAMA_MODEL = 'llama2:13b'
// o
const OLLAMA_MODEL = 'llama3.2'
```

Luego reinicia Trendo POS.

## Caracter√≠sticas del Nuevo Chatbot

‚ú® **Basado en IA**: Responde de forma natural y contextualizada
‚ú® **Acceso a datos**: Conoce autom√°ticamente tus ingresos, productos, clientes, etc.
‚ú® **Flexible**: Puedes hacer preguntas de muchas formas diferentes
‚ú® **Privado**: Todo funciona localmente en tu computadora
‚ú® **Offline**: Funciona sin conexi√≥n a internet

## Comando de Diagn√≥stico

Si tienes problemas, escribe en el chatbot:
```
debug
o
verificar
o
diagn√≥stico
```

Esto te mostrar√°:
- Cantidad de ventas registradas
- Cantidad de productos
- Cantidad de devoluciones
- Estado de Ollama

## Soporte

Si tienes problemas:
1. Ejecuta el comando `debug` en el chatbot
2. Verifica que Ollama est√© ejecut√°ndose
3. Revisa los logs en la consola del navegador (F12)

¬°Disfruta tu nuevo chatbot potenciado por IA! üöÄ
